{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ddfdf0",
   "metadata": {},
   "source": [
    "# Train the ML models on the new Draco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "draco_csv_filepath = \"draco-qoe-dataset/ratings.csv\"\n",
    "results_folder = \"./results_shivi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b6938",
   "metadata": {},
   "source": [
    "### From file resources.csv in the dataset\n",
    "\n",
    "| object     | quality | fps | bitrate  |\n",
    "|------------|---------|-----|----------|\n",
    "| dancer     | 0       | 10  | 182.471  |\n",
    "| dancer     | 0       | 15  | 273.511  |\n",
    "| dancer     | 0       | 30  | 547.29   |\n",
    "| dancer     | 1       | 10  | 245.245  |\n",
    "| dancer     | 1       | 15  | 367.644  |\n",
    "| dancer     | 1       | 30  | 735.539  |\n",
    "| dancer     | 2       | 10  | 321.263  |\n",
    "| dancer     | 2       | 15  | 481.527  |\n",
    "| dancer     | 2       | 30  | 963.341  |\n",
    "| dancer     | 3       | 10  | 405.436  |\n",
    "| dancer     | 3       | 15  | 607.569  |\n",
    "| dancer     | 3       | 30  | 1215.621 |\n",
    "| dancer     | 4       | 10  | 807.555  |\n",
    "| dancer     | 4       | 15  | 1209.734 |\n",
    "| dancer     | 4       | 30  | 2420.799 |\n",
    "| thaidancer | 0       | 10  | 286.915  |\n",
    "| thaidancer | 0       | 15  | 430.647  |\n",
    "| thaidancer | 0       | 30  | 860.277  |\n",
    "| thaidancer | 1       | 10  | 358.909  |\n",
    "| thaidancer | 1       | 15  | 538.603  |\n",
    "| thaidancer | 1       | 30  | 1076.053 |\n",
    "| thaidancer | 2       | 10  | 442.003  |\n",
    "| thaidancer | 2       | 15  | 663.315  |\n",
    "| thaidancer | 2       | 30  | 1325.233 |\n",
    "| thaidancer | 3       | 10  | 534.643  |\n",
    "| thaidancer | 3       | 15  | 802.233  |\n",
    "| thaidancer | 3       | 30  | 1602.851 |\n",
    "| thaidancer | 4       | 10  | 1002.921 |\n",
    "| thaidancer | 4       | 15  | 1504.548 |\n",
    "| thaidancer | 4       | 30  | 3006.424 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5657f5f2",
   "metadata": {},
   "source": [
    "### Control the training parameters from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROL THE PROGRAM HERE\n",
    "parameter_columns = [\"framerate\",\n",
    "    #\"duration\",\n",
    "    \"qp\",\n",
    "    \"bitrate\",\n",
    "    \"bpp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_level_to_draco_QP = {0: 8, 1: 9, 2: 10, 3: 11, 4: 16}\n",
    "\n",
    "# these distances are in \"units\" and idk what that is exactly\n",
    "draco_distance_map = {\"near\": 2.5, \"medium\": 4.5, \"far\": 8.5}\n",
    "\n",
    "quantization_level_to_bitrate = {\n",
    "    \"thaidancer\": {0: 860.277, 1: 1076.053, 2: 1325.233, 3: 1602.851, 4: 3006.424},\n",
    "    \"dancer\": {0: 547.29, 1: 735.539, 2: 963.341, 3: 1215.621, 4: 2420.799},\n",
    "}\n",
    "\n",
    "bits_per_point_map = {\"thaidancer\": 3078782, \"dancer\": 2608178}\n",
    "\n",
    "resolution_map = {\n",
    "    \"thaidancer\": 4096,  # 4096 x 4096 x 4096 point clouds\n",
    "    \"dancer\": 2048,  # 2048 x 2048 texture maps\n",
    "}\n",
    "\n",
    "save_subfolder_name = (lambda lst: '_'.join(lst))(parameter_columns)\n",
    "print(save_subfolder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e87b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using the boxplot method\n",
    "def boxplot_outlier_filter_draco(frame):\n",
    "    \"\"\"\n",
    "    Outlier filter using interquantile range (filter below Q1 - 1.5 IQR and above Q3 + 1.5 IQR)\n",
    "\n",
    "    :param frame: data frame\n",
    "    :return: filtered frame\n",
    "    \"\"\"\n",
    "    q1 = frame.quantile(0.25, numeric_only=True)[\"qoe\"]\n",
    "    q3 = frame.quantile(0.75, numeric_only=True)[\"qoe\"]\n",
    "\n",
    "    # interquantile range\n",
    "    iqr = q3 - q1\n",
    "    fence_low = q1 - (1.5 * iqr)\n",
    "    fence_high = q3 + (1.5 * iqr)\n",
    "\n",
    "    # filter the frame\n",
    "    filtered = (frame[\"qoe\"] >= fence_low) & (frame[\"qoe\"] <= fence_high)\n",
    "    return frame.loc[filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6170429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c15fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "draco_df = pd.read_csv(draco_csv_filepath)\n",
    "draco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9ee34",
   "metadata": {},
   "source": [
    "### only use the draco data, dont care about VPCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "draco_df = draco_df[draco_df[\"encode_method\"] == \"Draco\"]\n",
    "draco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e7787",
   "metadata": {},
   "source": [
    "### turn the distance into integer units rather than a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "draco_df[\"distance\"] = draco_df[\"distance\"].apply(lambda dist: draco_distance_map[dist])\n",
    "draco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02651df2",
   "metadata": {},
   "source": [
    "### change \"frame_rate\" to \"framerate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcabdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "draco_df = draco_df.rename(columns={\"frame_rate\": \"framerate\"})\n",
    "draco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e909b1",
   "metadata": {},
   "source": [
    "### process the quantization level index into draco quantization_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "draco_df[\"qp\"] = draco_df[\"quantization_level_index\"].apply(\n",
    "    lambda qp: quantization_level_to_draco_QP[qp]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e892a01",
   "metadata": {},
   "source": [
    "### add a bitrate parameter based on the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draco_df[\"bitrate\"] = draco_df.apply(\n",
    "    lambda row: quantization_level_to_bitrate[row.object][row.quantization_level_index], axis=1\n",
    ")\n",
    "\n",
    "draco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0867e5",
   "metadata": {},
   "source": [
    "#### add bits per point as a metric as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5870996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bits per point should be calculated for 30 frames per second\n",
    "# thus, total points are framerate * bits_per_point_map[object_name]\n",
    "\n",
    "draco_df[\"bpp\"] = draco_df.apply(\n",
    "    lambda row: row.bitrate / (row.framerate * bits_per_point_map[row.object]), axis=1\n",
    ")\n",
    "draco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb0777",
   "metadata": {},
   "source": [
    "### remove the 2d video size since we're not viewing on 2d screens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fdeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draco_df = draco_df[['object','framerate', 'distance', 'quantization_parameter', 'qoe']]\n",
    "\n",
    "draco_df = draco_df[\n",
    "    [\"object\"] \n",
    "    + parameter_columns\n",
    "    + [\"qoe\"]\n",
    "]\n",
    "draco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad2e4b",
   "metadata": {},
   "source": [
    "### Start processing the data to be used in the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "draco_df = draco_df[\n",
    "    parameter_columns + [\"qoe\"]\n",
    "]\n",
    "# groupby column names\n",
    "groupby_columns_draco = parameter_columns  # MAKE SURE GROUPBY COLUMNS DOESNT HAVE QOE!!!!\n",
    "\n",
    "configurations_draco = draco_df.groupby(groupby_columns_draco, as_index=False)\n",
    "configurations_draco\n",
    "\n",
    "filtered_draco_df = None\n",
    "\n",
    "# for each configuration, filter outliers\n",
    "for _, frame in configurations_draco:\n",
    "    filtered_draco_df = pd.concat(\n",
    "        [filtered_draco_df, boxplot_outlier_filter_draco(frame)], axis=0\n",
    "    )\n",
    "\n",
    "# reset the index of the filtered dataframe\n",
    "filtered_draco_df = filtered_draco_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_draco_df = None\n",
    "\n",
    "# Q1 = draco_df['qoe'].quantile(0.25)\n",
    "# Q3 = draco_df['qoe'].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# filtered_draco_df = draco_df[(draco_df['qoe'] >= lower_bound) & (draco_df['qoe']<= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd35a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'qoe' with 'rate' as a column name\n",
    "\n",
    "filtered_draco_df[\"rate\"] = filtered_draco_df[\"qoe\"]\n",
    "filtered_draco_df = filtered_draco_df[\n",
    "    parameter_columns + [\"rate\"]\n",
    "]\n",
    "filtered_draco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_draco = filtered_draco_df.groupby(groupby_columns_draco)\n",
    "groups_draco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# fn to separate cols into training and testing data\n",
    "def get_train_test_fold(groups, test_group_name):\n",
    "    \"\"\"\n",
    "    Get train/test folds for leave-one-out cross-validation.\n",
    "\n",
    "    :param test_group_name: the group name of the test fold\n",
    "    :param normalize: normalize the data with StandardScaler\n",
    "    :return: tuple with data frames (train features, train labels, test features, test labels)\n",
    "    \"\"\"\n",
    "    training_group_keys = list(groups.groups.keys())\n",
    "    training_group_keys.remove(test_group_name)\n",
    "    training_groups = pd.concat(list(map(groups.get_group, training_group_keys)))\n",
    "\n",
    "    y_train = training_groups[\"rate\"]\n",
    "    # The features must not contain the last column\n",
    "    x_train = training_groups.drop(\"rate\", axis=1)\n",
    "\n",
    "    # single test sample from test group\n",
    "    y_test = groups.get_group(test_group_name)[\"rate\"].mean()\n",
    "    x_test = groups.get_group(test_group_name).head(1).iloc[:, :-1]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 12563\n",
    "\n",
    "classifier_models = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=seed),\n",
    "    LogisticRegression(C=1, penalty=\"l2\", solver=\"liblinear\", random_state=seed),\n",
    "    GradientBoostingClassifier(\n",
    "        learning_rate=0.01, max_depth=5, n_estimators=100, random_state=seed\n",
    "    ),\n",
    "    DecisionTreeClassifier(random_state=seed),\n",
    "    MLPClassifier(\n",
    "        activation=\"relu\",\n",
    "        alpha=0.01,\n",
    "        hidden_layer_sizes=[10, 20],\n",
    "        max_iter=200,\n",
    "        solver=\"adam\",\n",
    "        random_state=seed,\n",
    "    ),\n",
    "]\n",
    "\n",
    "CODECS = [\"DRACO\"]\n",
    "GROUPS = [groups_draco]\n",
    "report = None\n",
    "\n",
    "for codec, group in zip(CODECS, GROUPS):\n",
    "    print(f\"Processing {codec}\")\n",
    "    for group_name in group.groups.keys():\n",
    "        # print('Groups')\n",
    "        # print(group.grouper.names)\n",
    "        # print(group.groups)\n",
    "        x_train, y_train, x_test, y_test = get_train_test_fold(group, group_name)\n",
    "\n",
    "        for model in classifier_models:\n",
    "            # print(f\"Processing {codec} with model {model.__class__.__name__}\")\n",
    "            # Print unique values in y_train to see what classes exist\n",
    "            # print(\"Unique classes in training data:\", np.unique(y_train))\n",
    "\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            # result of our model is the prediction of class probabilities per voting category\n",
    "            class_prob_prediction = model.predict_proba(x_test)\n",
    "\n",
    "            # Create results with probabilities for each class\n",
    "            results = pd.DataFrame(\n",
    "                class_prob_prediction,\n",
    "                columns=[\"prob_1\", \"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"],\n",
    "            )\n",
    "            results[\"test_configuration\"] = str(group_name)\n",
    "            results[\"model\"] = model.__class__.__name__\n",
    "\n",
    "            # Convert back from encoded to original classes for true_mos\n",
    "            results[\"true_mos\"] = y_test + 1  # Add 1 since LabelEncoder uses 0-4\n",
    "\n",
    "            # Calculate predicted MOS from probabilities\n",
    "            results[\"predicted_mos\"] = results.apply(\n",
    "                lambda row: np.sum([(i + 1) * p for i, p in enumerate(row[:5])]), axis=1\n",
    "            )\n",
    "            results[\"mse\"] = mean_squared_error(\n",
    "                results[\"true_mos\"], results[\"predicted_mos\"]\n",
    "            )\n",
    "\n",
    "            report = pd.concat([report, results], axis=0, ignore_index=True)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e2283",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e27a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "# report = None\n",
    "\n",
    "# regressor_models = [\n",
    "#     KNeighborsRegressor(leaf_size=10, n_neighbors=10),\n",
    "#     RandomForestRegressor(random_state=seed),\n",
    "#     Ridge(random_state=seed),\n",
    "#     Lasso(random_state=seed),\n",
    "#     GradientBoostingRegressor(random_state=seed),\n",
    "#     DecisionTreeRegressor(random_state=seed),\n",
    "#     MLPRegressor(random_state=seed),\n",
    "#     LinearRegression(),\n",
    "#     make_pipeline(PolynomialFeatures(2), preprocessing.StandardScaler(), LinearRegression())\n",
    "# ]\n",
    "\n",
    "# Updated regressor models\n",
    "regressor_models = [\n",
    "    RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=seed,\n",
    "    ),\n",
    "    GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=seed,\n",
    "    ),\n",
    "    ExtraTreesRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=seed,\n",
    "    ),\n",
    "    LinearRegression(),\n",
    "    make_pipeline(\n",
    "        PolynomialFeatures(degree=2), preprocessing.RobustScaler(), Ridge(alpha=0.1)\n",
    "    ),\n",
    "]\n",
    "\n",
    "for codec, group in zip(CODECS, GROUPS):\n",
    "    print(f\"Processing {codec}\")\n",
    "    for group_name in group.groups.keys():\n",
    "        x_train, y_train, x_test, y_test = get_train_test_fold(group, group_name)\n",
    "\n",
    "        for model in regressor_models:\n",
    "            # Fit model\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            # Get predictions\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            # Create results DataFrame\n",
    "            results = pd.DataFrame(\n",
    "                {\n",
    "                    \"true_mos\": y_test,\n",
    "                    \"predicted_mos\": y_pred,\n",
    "                    \"test_configuration\": str(group_name),\n",
    "                    \"model\": model.__class__.__name__,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # results = pd.DataFrame(mos_prediction, columns =['predicted_mos'])\n",
    "            # results['test_configuration'] = str(group_name)\n",
    "            # results['model'] = model.__class__.__name__\n",
    "            # results['true_mos'] = y_test\n",
    "            # results['predicted_mos'] =float(mos_prediction[0])\n",
    "            # results['mse'] = mean_squared_error(results['true_mos'], results['predicted_mos'])\n",
    "\n",
    "            # Calculate MSE per group\n",
    "            results[\"mse\"] = mean_squared_error(\n",
    "                results[\"true_mos\"], results[\"predicted_mos\"]\n",
    "            )\n",
    "\n",
    "            report = pd.concat([report, results], axis=0, ignore_index=True)\n",
    "\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8571c79",
   "metadata": {},
   "source": [
    "## Aggregate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c28e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score as R2\n",
    "import math\n",
    "\n",
    "model_performance = None\n",
    "\n",
    "for model, group_content in report.groupby(\"model\"):\n",
    "    single_model_performance = pd.DataFrame(\n",
    "        data=[\n",
    "            [\n",
    "                model,\n",
    "                R2(group_content[\"true_mos\"], group_content[\"predicted_mos\"]),\n",
    "                mean_squared_error(\n",
    "                    group_content[\"true_mos\"], group_content[\"predicted_mos\"]\n",
    "                ),\n",
    "                math.sqrt(\n",
    "                    mean_squared_error(\n",
    "                        group_content[\"true_mos\"], group_content[\"predicted_mos\"]\n",
    "                    )\n",
    "                ),\n",
    "                mean_absolute_error(\n",
    "                    group_content[\"true_mos\"], group_content[\"predicted_mos\"]\n",
    "                ),\n",
    "            ]\n",
    "        ],\n",
    "        columns=[\"model\", \"r2_score\", \"mse\", \"rmse\", \"mae\"],\n",
    "    )\n",
    "    model_performance = pd.concat(\n",
    "        [model_performance, single_model_performance], axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "model_performance = model_performance.sort_values(\n",
    "    [\"r2_score\", \"mse\", \"mae\"], ascending=False\n",
    ").reset_index(drop=True)\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "\n",
    "report_savedir = \"results_shivi\"    + \"/model_scores/draco/\"    + save_subfolder_name    + \"/\"\n",
    "os.makedirs(report_savedir, exist_ok=True)\n",
    "\n",
    "report.to_csv(\n",
    "    report_savedir\n",
    "    + \"performance_per_model_SHIVI_DRACO_\"\n",
    "    + now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    + \".csv\",\n",
    "    index=False,\n",
    ")\n",
    "model_performance.to_csv(\n",
    "    report_savedir\n",
    "    + \"models_scores_SHIVI_DRACO_\"\n",
    "    + now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    + \".csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58346a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "figure_savedir = \"./figures/\"         + save_subfolder_name         + \"/\"\n",
    "os.makedirs(figure_savedir, exist_ok=True)\n",
    "\n",
    "for model, group_content in report.groupby(\"model\"):\n",
    "    print(model)\n",
    "    # Generate the scatter plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(group_content[\"true_mos\"], group_content[\"predicted_mos\"])\n",
    "\n",
    "    # Add y=x line to the plot\n",
    "    plt.plot([0, 5], [0, 5], color=\"red\")\n",
    "\n",
    "    # Label the axes\n",
    "    plt.xlabel(\"Perceived MOS\")\n",
    "    plt.ylabel(\"Predicted MOS\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        figure_savedir\n",
    "        +\"predicted_and_true_distribution_\"\n",
    "        + model\n",
    "        + \"_DRACO_\"\n",
    "        + now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        + \".pdf\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb10e07",
   "metadata": {},
   "source": [
    "# Use the ML Model with Partners data to generate QoE results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268974d5",
   "metadata": {},
   "source": [
    "## Save the models using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44340bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# After training, save all models, not just the best ones\n",
    "\n",
    "# best_models = {}\n",
    "# for model_type in ['classifier', 'regressor']:\n",
    "#     model_data = model_performance[model_performance.model.str.contains(model_type, case=False)]\n",
    "#     best_model_name = model_data.sort_values('rmse', ascending=True).iloc[0]['model']\n",
    "#     best_models[model_type] = best_model_name\n",
    "\n",
    "# Create directories for saving models and scalers\n",
    "import os\n",
    "\n",
    "models_dir = \"./results_shivi/trained_models/\" + save_subfolder_name + \"/\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save all the models!\n",
    "for m in classifier_models:\n",
    "    # Save model\n",
    "    model_path = os.path.join(\n",
    "        models_dir, f\"{m.__class__.__name__}_{now.strftime('%Y%m%d_%H%M%S')}.joblib\"\n",
    "    )\n",
    "    dump(m, model_path)\n",
    "\n",
    "    print(f\"Saved {m.__class__.__name__} model to: {model_path}\")\n",
    "\n",
    "\n",
    "# Save all the models!\n",
    "for m in regressor_models:\n",
    "    # Save model\n",
    "    model_path = os.path.join(\n",
    "        models_dir, f\"{m.__class__.__name__}_{now.strftime('%Y%m%d_%H%M%S')}.joblib\"\n",
    "    )\n",
    "    dump(m, model_path)\n",
    "\n",
    "    print(f\"Saved {m.__class__.__name__} model to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88682b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FOR IMMEDIATE MODEL USAGE PURPOSES\\n\")\n",
    "\n",
    "print(\"DateTime used in filename\")\n",
    "print(now.strftime('%Y%m%d_%H%M%S'))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Training Parameter Columns\")\n",
    "print(parameter_columns)\n",
    "\n",
    "\n",
    "print(\"Save subfolder name\")\n",
    "print(save_subfolder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08603ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "\n",
    "model_names = [\n",
    "    \"RandomForestClassifier\",\n",
    "    \"LogisticRegression\",\n",
    "    \"GradientBoostingClassifier\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"MLPClassifier\",\n",
    "    \"RandomForestRegressor\",\n",
    "    \"GradientBoostingRegressor\",\n",
    "    \"ExtraTreesRegressor\",\n",
    "    \"LinearRegression\",\n",
    "    \"Pipeline\",\n",
    "]\n",
    "\n",
    "# CHANGE THESE FOR USAGE\n",
    "model_timestamp = \"20250710_154130\"\n",
    "# model_timestamp = now.strftime('%Y%m%d_%H%M%S')\n",
    "current_model_name = \"ExtraTreesRegressor\"\n",
    "# model_folder_name = \"framerate_qp_bitratembits\"\n",
    "model_folder_name = \"framerate_qp_bitratembits\"\n",
    "\n",
    "model = load(\n",
    "    f\"./results_shivi/trained_models/{model_folder_name}/{current_model_name}_{model_timestamp}.joblib\"\n",
    ")\n",
    "\n",
    "# Prepare new data\n",
    "new_data = pd.DataFrame(\n",
    "    {\n",
    "        \"framerate\": [30],\n",
    "        #\"duration\": [4534],\n",
    "        \"qp\": [14],\n",
    "        \"bitrate\": [55],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "prediction = model.predict(new_data)\n",
    "print(f\"Predicted MOS: {prediction[0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
