{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITU-T P.1203 Model Fine-Tuning\n",
    "\n",
    "Based on our subjective testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "**07.11**\n",
    "So I believe the bitrate values are all wrong here\n",
    "Firstly, Minh also appears to have used mbps in the p1203 calculation, which is wrong (or maybe was right at the time of the previous fine-tuning)\n",
    "Now the p1203 model clearly uses kbits/second\n",
    "\n",
    "I am collecting all video bitrates in bytes and then converting them to mbits/second, before multiplying them by 1000 to get kbits/second\n",
    "I am also only storing the bitrate in kbits to avoid confusion\n",
    "\n",
    "The way to get the megabits values is:\n",
    "1. get the size of the bin file in bytes (or kilobytes)\n",
    "2. convert it to megabits by dividing by 125000\n",
    "3. divide it by 10 (since the bin file is for 10-seconds) to get megabits / second\n",
    "4. multiply it by 1000 to get kbit/s\n",
    "All of our sequences are 10-second sequences, thus we divide by 10\n",
    "\n",
    "The video bitrates are as follows:\n",
    "```\n",
    "BlueSpin-r1.bin: 14000.33 kilobits\n",
    "BlueSpin-r2.bin: 18358.77 kilobits\n",
    "BlueSpin-r3.bin: 25381.74 kilobits\n",
    "BlueSpin-r4.bin: 60218.56 kilobits\n",
    "BlueSpin-r5.bin: 100957.13 kilobits\n",
    "CasualSquat-r1.bin: 20028.41 kilobits\n",
    "CasualSquat-r2.bin: 31350.91 kilobits\n",
    "CasualSquat-r3.bin: 53280.41 kilobits\n",
    "CasualSquat-r4.bin: 156102.30 kilobits\n",
    "CasualSquat-r5.bin: 248934.89 kilobits\n",
    "FlowerDance-r1.bin: 21305.45 kilobits\n",
    "FlowerDance-r2.bin: 33934.77 kilobits\n",
    "FlowerDance-r3.bin: 57028.55 kilobits\n",
    "FlowerDance-r4.bin: 182492.95 kilobits\n",
    "FlowerDance-r5.bin: 314833.07 kilobits\n",
    "longdress-r1.bin: 45330.51 kilobits\n",
    "longdress-r3.bin: 137209.71 kilobits\n",
    "longdress-r5.bin: 456825.40 kilobits\n",
    "loot-r1.bin: 22223.74 kilobits\n",
    "loot-r3.bin: 54941.94 kilobits\n",
    "loot-r5.bin: 162842.81 kilobits\n",
    "ReadyForWinter-r1.bin: 15823.20 kilobits\n",
    "ReadyForWinter-r2.bin: 20687.30 kilobits\n",
    "ReadyForWinter-r3.bin: 28919.76 kilobits\n",
    "ReadyForWinter-r4.bin: 74742.73 kilobits\n",
    "ReadyForWinter-r5.bin: 132748.28 kilobits\n",
    "redandblack-r1.bin: 33068.13 kilobits\n",
    "redandblack-r3.bin: 73753.55 kilobits\n",
    "redandblack-r5.bin: 223673.06 kilobits\n",
    "soldier-r1.bin: 42745.16 kilobits\n",
    "soldier-r3.bin: 113102.48 kilobits\n",
    "soldier-r5.bin: 344626.97 kilobits\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itu_p1203 import P1203Standalone\n",
    "from itu_p1203 import P1203Pq\n",
    "from itu_p1203 import P1203Pa\n",
    "from itu_p1203 import P1203Pv\n",
    "from itertools import permutations\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.optimize import minimize, Bounds, differential_evolution, basinhopping, brute, shgo, dual_annealing, direct\n",
    "from enum import Enum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths to Mode 0 template JSON files\n",
    "oldtests_mode0_json_filepath = './mode0-oldtests.json'\n",
    "newtests_mode0_json_filepath = './mode0-newtests.json'\n",
    "bothtests_mode0_json_filepath = './mode0-bothtests.json'\n",
    "\n",
    "# User QoE Scores CSV File\n",
    "qoe_csv_filepath = './results/test_scores.csv'\n",
    "\n",
    "# Bitrate and resolution information for all the videos in KBPS\n",
    "\n",
    "# New aka ComPEQ-MR Dataset\n",
    "bitrates_kbps_new = {\n",
    "    'BlueSpin': {'r01': 14000.33, 'r02': 18358.77, 'r03': 25381.74, 'r04': 60218.56, 'r05': 100957.13},\n",
    "    'CasualSquat':  {'r01': 20028.41, 'r02': 31350.91, 'r03': 53280.41, 'r04': 156102.30, 'r05': 248934.89},\n",
    "    'ReadyForWinter': { 'r01': 15823.20, 'r02': 20687.30, 'r03': 28919.76, 'r04': 74742.73, 'r05': 132748.28 },\n",
    "    'FlowerDance': { 'r01': 21305.45,  'r02': 33934.77,  'r03': 57028.55, 'r04': 182492.95, 'r05': 314833.07}\n",
    "}\n",
    "\n",
    "resolution_map_new = {\n",
    "    'r01': '640x360', # worse than 420p\n",
    "    'r02': '852x480', # exactly 480p\n",
    "    'r03': '1192x672', # bit worse than 720p\n",
    "    'r04': '1533x864', # a bit better than 720p\n",
    "    'r05': '1920x1080', # exactly 1080p\n",
    "}\n",
    "\n",
    "distance_map_new = {\n",
    "    'd200' : '200cm'\n",
    "}\n",
    "\n",
    "# Old dataset from first round of subjective testing\n",
    "bitrates_kbps_old = {\n",
    "    'LongDress': { 'r1': 45330.51, 'r3': 137209.71, 'r5': 456825.40 },\n",
    "    'Loot': { 'r1': 22223.74, 'r3': 54941.94, 'r5': 162842.81 },\n",
    "    'RedAndBlack': { 'r1': 33068.13, 'r3': 73753.55, 'r5': 223673.06 },\n",
    "    'Soldier': { 'r1': 42745.16, 'r3': 113102.48, 'r5': 344626.97 }\n",
    "}\n",
    "\n",
    "resolution_map_old = {\n",
    "    'r1': '854x480', # old dataset 480p\n",
    "    'r3': '1280x720', # old dataset 720p\n",
    "    'r5': '1920x1080' # old dataset 1080p\n",
    "}\n",
    "\n",
    "distance_map_old = {\n",
    "    'd125' : '125cm',\n",
    "    'd250' : '250cm',\n",
    "    'd500' : '500cm'\n",
    "}\n",
    "\n",
    "# Default P1203 coefficients\n",
    "_COEFFS = {\n",
    "        'u1': 72.61,\n",
    "        'u2': 0.32,\n",
    "        't1': 30.98,\n",
    "        't2': 1.29,\n",
    "        't3': 64.65,\n",
    "        'q1': 4.66,\n",
    "        'q2': -0.07,\n",
    "        'q3': 4.06,\n",
    "        'mode0': {\n",
    "            'a1': 11.9983519,\n",
    "            'a2': -2.99991847,\n",
    "            'a3': 41.2475074001,\n",
    "            'a4': 0.13183165961,\n",
    "        },\n",
    "        'mode1': {\n",
    "            'a1': 5.00011566,\n",
    "            'a2': -1.19630824,\n",
    "            'a3': 41.3585049,\n",
    "            'a4': 0,\n",
    "            'c0': -0.91562479,\n",
    "            'c1': 0,\n",
    "            'c2': -3.28579526,\n",
    "            'c3': 20.4098663,\n",
    "        },\n",
    "        'htv_1': -0.60293,\n",
    "        'htv_2': 2.12382,\n",
    "        'htv_3': -0.36936,\n",
    "        'htv_4': 0.03409,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling the Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Flags\n",
    "old_tests = True\n",
    "new_tests = True\n",
    "\n",
    "# Set the training and the validation point cloud object names\n",
    "\n",
    "if old_tests and new_tests:\n",
    "    training_object_names = ['BlueSpin', 'CasualSquat', 'LongDress', 'Loot']\n",
    "    validation_object_names = ['ReadyForWinter', 'FlowerDance', 'RedAndBlack', 'Soldier']\n",
    "elif old_tests:\n",
    "    training_object_names = ['LongDress', 'Loot']\n",
    "    validation_object_names = ['RedAndBlack', 'Soldier']\n",
    "else:\n",
    "    training_object_names = ['BlueSpin', 'CasualSquat']\n",
    "    validation_object_names = ['ReadyForWinter', 'FlowerDance']\n",
    "\n",
    "# Load the Input Json\n",
    "if old_tests and new_tests:\n",
    "    f = open(bothtests_mode0_json_filepath)\n",
    "elif old_tests:\n",
    "    f = open(oldtests_mode0_json_filepath)\n",
    "else:\n",
    "    f = open(newtests_mode0_json_filepath)\n",
    "\n",
    "input_json = json.load(f)\n",
    "\n",
    "# Set the suffix for the savefile names\n",
    "if old_tests and new_tests:\n",
    "    graph_savename_suffix = '_BOTH'\n",
    "elif old_tests:\n",
    "    graph_savename_suffix = '_OLD'\n",
    "else:\n",
    "    graph_savename_suffix = '_NEW'\n",
    "\n",
    "# Optimization Methods\n",
    "#optimization_methods = ['basinhopping', 'brute', 'differential_evolution', 'shgo', 'dual_annealing', 'direct']\n",
    "optimization_methods = ['shgo', 'dual_annealing', 'brute'] # only using these three methods for now\n",
    "\n",
    "current_optimization_method = None # if this is none then we go through all the ones above!\n",
    "#current_optimization_method = 'dual_annealing'\n",
    "\n",
    "#bounds = [(-5,30), (-10, 10), (-10, 160), (-10, 10)]\n",
    "bounds = [(1,15), (-5, 5), (0, 80), (0, 5)]\n",
    "\n",
    "# Training or validation\n",
    "class DatasetType(Enum):\n",
    "    TRAINING = 1,\n",
    "    VALIDATION = 2\n",
    "\n",
    "# groupby column names\n",
    "groupby_columns = ['object', 'start_qual', 'end_qual', 'dist']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the object string into object, start_qual, end_qual, and distance\n",
    "def split_object_column(object_string):\n",
    "    if 'BlueSpin' in object_string or 'FlowerDance' in object_string or 'ReadyForWinter' in object_string or 'CasualSquat' in object_string:\n",
    "        split_string = object_string.split('_')\n",
    "        split_string[1] = split_string[2]\n",
    "        return split_string\n",
    "    elif 'LongDress' in object_string or 'Loot' in object_string or 'Soldier' in object_string or 'RedAndBlack' in object_string:\n",
    "        return object_string.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using the boxplot method\n",
    "def boxplot_outlier_filter(frame):\n",
    "    \"\"\"\n",
    "    Outlier filter using interquantile range (filter below Q1 - 1.5 IQR and above Q3 + 1.5 IQR)\n",
    "\n",
    "    :param frame: data frame\n",
    "    :return: filtered frame\n",
    "    \"\"\"\n",
    "    q1 = frame.quantile(0.25, numeric_only=True)['rate']\n",
    "    q3 = frame.quantile(0.75, numeric_only=True)['rate']\n",
    "\n",
    "    # interquantile range\n",
    "    iqr = q3 - q1\n",
    "    fence_low = q1 - (1.5 * iqr)\n",
    "    fence_high = q3 + (1.5 * iqr)\n",
    "\n",
    "    # filter the frame\n",
    "    filtered = (frame['rate'] >= fence_low) & (frame['rate'] <= fence_high)\n",
    "    return frame.loc[filtered]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE of Groundtruth and P1203 QoE data\n",
    "def calculate_rmse(ground_truth, p1203_results):\n",
    "    p1203_results = p1203_results[['object', 'start_qual', 'end_qual', 'dist', 'p1203_qoe']]\n",
    "    ground_truth = ground_truth[['object', 'start_qual', 'end_qual', 'dist', 'rate']]\n",
    "    joined_qoe_results = p1203_results.merge(ground_truth)\n",
    "    rmse_arr = []\n",
    "    for idx in np.arange(joined_qoe_results.shape[0]):\n",
    "        # Get all the ratings for this object and qualities by the user\n",
    "        targets = joined_qoe_results.iloc[idx,:]['rate'] \n",
    "\n",
    "        # Get the P1203 rating for this object and quality and span it across all user ratings\n",
    "        predictions = np.full(len(targets), joined_qoe_results.loc[joined_qoe_results.index[idx], 'p1203_qoe']) \n",
    "\n",
    "        # get the RMSE between the p1203 and the user ratings\n",
    "        rmse_arr.append(np.sqrt(np.mean((predictions-targets)**2))) \n",
    "    return np.average(rmse_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scatter graph of predicted qoe and ground truth\n",
    "def make_scatter_graph(qoe_ground_truth, p1203_qoe, savefile_name, prediction_mode_label):\n",
    "    plt.scatter(qoe_ground_truth, p1203_qoe)\n",
    "    plt.plot([1, 5], [1, 5], color = 'red')\n",
    "    plt.xlabel(\"Ground Truth\")\n",
    "    plt.ylabel(prediction_mode_label)\n",
    "    \n",
    "    plt.suptitle(\"Ground Truth vs QoE \" + savefile_name + graph_savename_suffix)\n",
    "\n",
    "    plt.savefig(\"./figures/\" + savefile_name + graph_savename_suffix + \".pdf\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Spearman and Pearson coefficients of QoE and Groundtruth data\n",
    "def calculate_and_save_spearman_and_pearson(qoe_ground_truth, p1203_qoe, savefile_name):\n",
    "    df_correlation = pd.DataFrame({'Ground truth': qoe_ground_truth, 'P.1203': p1203_qoe})\n",
    "    \n",
    "    # Spearman Correlation\n",
    "    spear_corr = df_correlation.corr(method='spearman')\n",
    "    print(\"Spearmann Correlation\")\n",
    "    print(spear_corr)\n",
    "\n",
    "    plt.imshow(spear_corr, cmap='YlGnBu')\n",
    "\n",
    "    plt.suptitle(\"Spearman Correlation \" + savefile_name + graph_savename_suffix)\n",
    "    \n",
    "    plt.text(0, 0, spear_corr['Ground truth']['Ground truth'], ha = 'center', va = 'center', color = 'w')\n",
    "    plt.text(1, 0, spear_corr['Ground truth']['P.1203'], ha = 'center', va = 'center', color = 'black')\n",
    "    plt.text(0, 1, spear_corr['P.1203']['Ground truth'], ha = 'center', va = 'center', color = 'black')\n",
    "    plt.text(1, 1, spear_corr['P.1203']['P.1203'], ha = 'center', va = 'center', color = 'w')\n",
    "\n",
    "    plt.savefig(\"./figures/\" + savefile_name + \"_spearman\" + graph_savename_suffix + \".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # Pearson Correlation\n",
    "    pear_corr = df_correlation.corr(method='pearson')\n",
    "    print(\"Pearson Correlation\")\n",
    "    print(pear_corr)\n",
    "\n",
    "    plt.imshow(pear_corr, cmap='YlGnBu')\n",
    "\n",
    "    plt.suptitle(\"Pearson Correlation \" + savefile_name + graph_savename_suffix)\n",
    "\n",
    "    plt.text(0, 0, pear_corr['Ground truth']['Ground truth'], ha = 'center', va = 'center', color = 'w')\n",
    "    plt.text(1, 0, pear_corr['Ground truth']['P.1203'], ha = 'center', va = 'center', color = 'black')\n",
    "    plt.text(0, 1, pear_corr['P.1203']['Ground truth'], ha = 'center', va = 'center', color = 'black')\n",
    "    plt.text(1, 1, pear_corr['P.1203']['P.1203'], ha = 'center', va = 'center', color = 'w')\n",
    "\n",
    "    plt.savefig(\"./figures/\" + savefile_name + \"_pearson\" + graph_savename_suffix + \".pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P1203 for everything based on specified weights\n",
    "def calculate_p1203_for_everything(input_json, current_coeffs=None):\n",
    "    p1203_results = {\n",
    "        'object': [],\n",
    "        'start_qual': [],\n",
    "        'end_qual': [],\n",
    "        'start_bitrate': [],\n",
    "        'end_bitrate': [],\n",
    "        'dist' : [],\n",
    "        'p1203_qoe': [],\n",
    "    }\n",
    "\n",
    "    # Calculate P1203 for old videos\n",
    "    if old_tests:\n",
    "        for video in list(bitrates_kbps_old.keys()):\n",
    "            # Loot and LongDress had quality switches\n",
    "            if video == 'Loot' or video == 'LongDress':\n",
    "                bitrate_permutations = permutations(list(bitrates_kbps_old[video].values()), 2)\n",
    "                quality_permutations = permutations(list(bitrates_kbps_old[video].keys()), 2)\n",
    "                \n",
    "                bitrates=list(bitrate_permutations)\n",
    "                qualities = list(quality_permutations)\n",
    "\n",
    "                for bitrate in list(bitrates_kbps_old[video].values()):\n",
    "                    bitrates.append((bitrate, bitrate))\n",
    "                \n",
    "                for quality in list(bitrates_kbps_old[video].keys()):\n",
    "                    qualities.append((quality, quality))\n",
    "\n",
    "                # Loot and LongDress were always at 500cm\n",
    "                distances = list([distance_map_old['d500']])\n",
    "\n",
    "            # Soldier and RedAndBlack had static qualities\n",
    "            elif video == 'Soldier'or video == 'RedAndBlack':\n",
    "                bitrates = list(bitrates_kbps_old[video].values())\n",
    "                qualities = list(bitrates_kbps_old[video].keys())\n",
    "\n",
    "                # Soldier and RedAndBlack were at different distances\n",
    "                distances = list(distance_map_old.values())\n",
    "\n",
    "            for distance in distances:\n",
    "                for bitrate, quality in zip(bitrates, qualities):\n",
    "                    \n",
    "                    p1203_results['object'].append(video)\n",
    "\n",
    "                    # Loot and LongDress had quality switches\n",
    "                    if video == 'Loot' or video == 'LongDress':\n",
    "                        p1203_results['start_qual'].append(quality[0])\n",
    "                        p1203_results['end_qual'].append(quality[1])\n",
    "                        p1203_results['start_bitrate'].append(bitrate[0])\n",
    "                        p1203_results['end_bitrate'].append(bitrate[1])\n",
    "\n",
    "                        input_json['I13']['segments'][0]['bitrate'] = bitrate[0]\n",
    "                        input_json['I13']['segments'][0]['resolution'] = resolution_map_old[quality[0]]\n",
    "                        input_json['I13']['segments'][1]['bitrate'] = bitrate[1]\n",
    "                        input_json['I13']['segments'][1]['resolution'] = resolution_map_old[quality[1]]\n",
    "                    \n",
    "                    # Soldier and RedAndBlack had static qualities\n",
    "                    elif video == 'Soldier'or video == 'RedAndBlack':\n",
    "                        p1203_results['start_qual'].append(quality)\n",
    "                        p1203_results['end_qual'].append(quality)\n",
    "                        p1203_results['start_bitrate'].append(bitrate)\n",
    "                        p1203_results['end_bitrate'].append(bitrate)\n",
    "\n",
    "                        input_json['I13']['segments'][0]['bitrate'] = bitrate\n",
    "                        input_json['I13']['segments'][0]['resolution'] = resolution_map_old[quality]\n",
    "                        input_json['I13']['segments'][1]['bitrate'] = bitrate\n",
    "                        input_json['I13']['segments'][1]['resolution'] = resolution_map_old[quality]\n",
    "\n",
    "                    # the old dataset videos are 30 fps and 10 seconds in sequence length\n",
    "                    input_json['I13']['segments'][0]['fps'] = 30\n",
    "                    input_json['I13']['segments'][1]['fps'] = 30\n",
    "                    input_json['I13']['segments'][0]['duration'] = 5\n",
    "                    input_json['I13']['segments'][1]['duration'] = 5\n",
    "                    input_json['I13']['segments'][1]['start'] = 5\n",
    "\n",
    "                    input_json['IGen']['viewingDistance'] = distance\n",
    "\n",
    "                    # print(\"Video: \" + str(video) + \n",
    "                    #         \", Start bitrate: \" + str(input_json['I13']['segments'][0]['bitrate']) + \n",
    "                    #         \", Start qual: \" + str(quality) + \n",
    "                    #         \", End bitrate: \" + str(input_json['I13']['segments'][1]['bitrate']) + \n",
    "                    #         \", End qual: \" + str(quality) +\n",
    "                    #         \", Distance: \" + input_json['IGen']['viewingDistance'])\n",
    "\n",
    "                    if current_coeffs is None:\n",
    "                        p1203_qoe = P1203Standalone(input_json).calculate_complete()['O46']\n",
    "                    else:\n",
    "                        p1203_qoe = P1203Standalone(input_json, coeffs=current_coeffs).calculate_complete()['O46']\n",
    "\n",
    "                    p1203_results['dist'].append(distance)\n",
    "                    p1203_results['p1203_qoe'].append(p1203_qoe)\n",
    "    \n",
    "    # Calculate P1203 for new videos\n",
    "    if new_tests:\n",
    "        for video in list(bitrates_kbps_new.keys()):   \n",
    "            bitrates = list(bitrates_kbps_new[video].values())\n",
    "            qualities = list(bitrates_kbps_new[video].keys())\n",
    "            distances = list([distance_map_new['d200']]) # New videos the user could move around but the starting distance was always 200cm\n",
    "\n",
    "            for distance in distances:\n",
    "                for bitrate, quality in zip(bitrates, qualities):\n",
    "                    p1203_results['object'].append(video)\n",
    "                    p1203_results['start_qual'].append(quality)\n",
    "                    p1203_results['end_qual'].append(quality)\n",
    "                    p1203_results['start_bitrate'].append(bitrate)\n",
    "                    p1203_results['end_bitrate'].append(bitrate)\n",
    "\n",
    "                    input_json['I13']['segments'][0]['bitrate'] = bitrate\n",
    "                    input_json['I13']['segments'][0]['resolution'] = resolution_map_new[quality]\n",
    "                    input_json['I13']['segments'][1]['bitrate'] = bitrate\n",
    "                    input_json['I13']['segments'][1]['resolution'] = resolution_map_new[quality]\n",
    "\n",
    "                    # the ComPEQ-MR videos are 25 fps and 20 seconds in sequence length\n",
    "                    input_json['I13']['segments'][0]['fps'] = 25\n",
    "                    input_json['I13']['segments'][1]['fps'] = 25\n",
    "                    input_json['I13']['segments'][0]['duration'] = 10\n",
    "                    input_json['I13']['segments'][1]['duration'] = 10\n",
    "                    input_json['I13']['segments'][1]['start'] = 10 # make sure to mark the start of the second segment at 10 seconds for new videos\n",
    "\n",
    "                    input_json['IGen']['viewingDistance'] = distance\n",
    "\n",
    "                    # print(\"Video: \" + str(video) + \n",
    "                    #         \", Start bitrate: \" + str(input_json['I13']['segments'][0]['bitrate']) + \n",
    "                    #         \", Start qual: \" + str(quality) + \n",
    "                    #         \", End bitrate: \" + str(input_json['I13']['segments'][1]['bitrate']) + \n",
    "                    #         \", End qual: \" + str(quality) +\n",
    "                    #         \", Distance: \" + input_json['IGen']['viewingDistance'])\n",
    "\n",
    "                    if current_coeffs is None:\n",
    "                        p1203_qoe = P1203Standalone(input_json).calculate_complete()['O46']\n",
    "                    else:\n",
    "                        p1203_qoe = P1203Standalone(input_json, coeffs=current_coeffs).calculate_complete()['O46']\n",
    "\n",
    "                    p1203_results['dist'].append(distance)\n",
    "                    p1203_results['p1203_qoe'].append(p1203_qoe)\n",
    "        \n",
    "    return p1203_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a set of p1203 results and groundtruth dataframes\n",
    "def process_p1203_and_groundtruth(p1203_df, ground_truth_df, filename_prefix, dataset_type, yaxis_label):\n",
    "    if dataset_type is DatasetType.TRAINING:\n",
    "        # Get the training objects from the overall p1203_df\n",
    "        p1203_df_sliced = p1203_df.loc[p1203_df['object'].isin(training_object_names)]\n",
    "    elif dataset_type is DatasetType.VALIDATION:\n",
    "        # Get the validation objects from the overall p1203_df\n",
    "        p1203_df_sliced = p1203_df.loc[p1203_df['object'].isin(validation_object_names)]\n",
    "\n",
    "    # Group the data by object name, start quality, and end quality\n",
    "    p1203_df_grouped = p1203_df_sliced.groupby(groupby_columns,as_index=False)\n",
    "\n",
    "    # Take a mean of the qoe values that are grouped at the end\n",
    "    p1203_df_grouped_mean = p1203_df_grouped.mean()\n",
    "\n",
    "    # Make a list from the grouped values\n",
    "    p1203_qoe_list = list(p1203_df_grouped_mean['p1203_qoe'])\n",
    "\n",
    "    # Print the data\n",
    "    print(\"--p1203_qoe_list--\")\n",
    "    print(p1203_qoe_list)\n",
    "\n",
    "    if dataset_type is DatasetType.TRAINING:\n",
    "        # Get only the training object data\n",
    "        ground_truth_sliced = ground_truth_df.loc[ground_truth_df['object'].isin(training_object_names)]\n",
    "    elif dataset_type is DatasetType.VALIDATION:\n",
    "        # Get only the validation object data\n",
    "        ground_truth_sliced = ground_truth_df.loc[ground_truth_df['object'].isin(validation_object_names)]\n",
    "\n",
    "    # Group the data by object name and qualities\n",
    "    ground_truth_sliced_grouped = ground_truth_sliced.groupby(groupby_columns, as_index=False)\n",
    "\n",
    "    # Mean the grouped ratings\n",
    "    ground_truth_sliced_mean = ground_truth_sliced_grouped.mean(numeric_only=True)\n",
    "\n",
    "    # Print the data\n",
    "    print(\"--ground_truth_sliced_mean\" +\" \" + str(dataset_type.name) + \"--\")\n",
    "    print(ground_truth_sliced_mean)\n",
    "\n",
    "    # Get the qoe scores from the training data\n",
    "    qoe_ground_truth_sliced = list(ground_truth_sliced_mean['rate'])\n",
    "\n",
    "    # Print the scores\n",
    "    print(\"--qoe_ground_truth_sliced\" +\" \" + str(dataset_type.name) + \"--\")\n",
    "    print(qoe_ground_truth_sliced)\n",
    "\n",
    "    # Plot the ground truth vs the results of the original model on training data\n",
    "    make_scatter_graph(qoe_ground_truth_sliced, p1203_qoe_list, filename_prefix + \"_scatter_\" + dataset_type.name, yaxis_label + \" \" + dataset_type.name)\n",
    "\n",
    "    # Calculate and display the RMSE\n",
    "    current_rmse = calculate_rmse(ground_truth_sliced_grouped.aggregate(lambda x: tuple(x)), p1203_df_grouped.aggregate(lambda x: tuple(x)))\n",
    "    print(yaxis_label + \" \" + dataset_type.name + \" RMSE: \" + str(current_rmse))\n",
    "\n",
    "    # Get Spearman and Pearson coefficients of this model and training data\n",
    "    calculate_and_save_spearman_and_pearson(qoe_ground_truth_sliced, p1203_qoe_list, filename_prefix)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to minimize\n",
    "def objective_function(trial_coeffs, input_json, ground_truth_qoe_grouped_training_df):\n",
    "    current_coeffs = _COEFFS\n",
    "\n",
    "    current_coeffs['mode0']['a1'] = trial_coeffs[0].item()\n",
    "    current_coeffs['mode0']['a2'] = trial_coeffs[1].item()\n",
    "    current_coeffs['mode0']['a3'] = trial_coeffs[2].item()\n",
    "    current_coeffs['mode0']['a4'] = trial_coeffs[3].item()\n",
    "\n",
    "    print(\"Current Coeffs: \" + str(current_coeffs['mode0']['a1']) + \" \" + str(current_coeffs['mode0']['a2']) + \" \" + str(current_coeffs['mode0']['a3']) + \" \" + str(current_coeffs['mode0']['a4']))\n",
    "    \n",
    "    p1203_qoe_dict = calculate_p1203_for_everything(input_json=input_json, current_coeffs=current_coeffs)\n",
    "    p1203_df = pd.DataFrame.from_dict(p1203_qoe_dict)\n",
    "    p1203_df = p1203_df.loc[p1203_df['object'].isin(training_object_names)]\n",
    "    p1203_qoe_grouped_training_mean = p1203_df.groupby(groupby_columns, as_index=False).mean()\n",
    "\n",
    "    \n",
    "    rmse = calculate_rmse(ground_truth=ground_truth_qoe_grouped_training_df, p1203_results=p1203_qoe_grouped_training_mean)\n",
    "    print(\"Current RMSE: \" + str(rmse))\n",
    "    \n",
    "    return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metrics of the Original Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Model Training and Validation Data Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the P1203 results for everything with the default weights\n",
    "p1203_results = calculate_p1203_for_everything(input_json)\n",
    "\n",
    "# Make a df from the p1203 results dict\n",
    "p1203_df = pd.DataFrame.from_dict(p1203_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue from reading the test scores of both tests\n",
    "\n",
    "# Read scores of both tests\n",
    "ground_truth_df = pd.read_csv(qoe_csv_filepath)\n",
    "\n",
    "# Split the columns of the ground truth data to get quality and other information\n",
    "ground_truth_df[['object', 'start_qual', 'end_qual', 'dist']] = pd.DataFrame(ground_truth_df['objects'].apply(split_object_column).to_list())\n",
    "\n",
    "# Print the data\n",
    "print(\"--ground_truth_df--\")\n",
    "print(ground_truth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the graphs and all the metrics for the original model on the validation dataset\n",
    "process_p1203_and_groundtruth(p1203_df=p1203_df, ground_truth_df=ground_truth_df, filename_prefix=\"original\", dataset_type=DatasetType.TRAINING, yaxis_label=\"ORIGINAL MODEL\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the graphs and all the metrics for the original model on the training dataset\n",
    "process_p1203_and_groundtruth(p1203_df=p1203_df, ground_truth_df=ground_truth_df, filename_prefix=\"original\", dataset_type=DatasetType.VALIDATION, yaxis_label=\"ORIGINAL MODEL\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(current_optimization_method, ground_truth_training_grouped_df):\n",
    "    print(\"Optimization method: \" + str(current_optimization_method))\n",
    "\n",
    "    match current_optimization_method:\n",
    "        case 'brute':\n",
    "            # optimize the results using brute force\n",
    "            (x0, fval, grid, Jout) = brute(objective_function, args=(input_json, ground_truth_training_grouped_df), ranges=bounds, full_output=True, finish=None, workers=-1)\n",
    "            \n",
    "            # print the results\n",
    "            print(\"x0: \" + str(x0))\n",
    "            print(\"fval: \" + str(fval))\n",
    "            print(\"grid: \" + str(grid))\n",
    "            print(\"Jout: \" + str(Jout))\n",
    "\n",
    "            return (x0, fval)\n",
    "\n",
    "        case 'shgo':\n",
    "            result = shgo(objective_function, args=(input_json, ground_truth_training_grouped_df), bounds=bounds, workers=-1)\n",
    "\n",
    "            print(\"Optimal Coeffs \" + current_optimization_method + \": \" + str(result.x))\n",
    "            print(\"Objective function RMSE value \" + current_optimization_method + \": \" + str(result.fun))\n",
    "            print(\"Objective function message \" + current_optimization_method + \": \" + str(result.message))\n",
    "\n",
    "            return (result.x, result.fun)\n",
    "\n",
    "        case 'dual_annealing':\n",
    "            result = dual_annealing(objective_function, args=(input_json, ground_truth_training_grouped_df), bounds=bounds)\n",
    "\n",
    "            print(\"Optimal Coeffs \" + current_optimization_method + \": \" + str(result.x))\n",
    "            print(\"Objective function RMSE value \" + current_optimization_method + \": \" + str(result.fun))\n",
    "            print(\"Objective function message \" + current_optimization_method + \": \" + str(result.message))\n",
    "\n",
    "            return (result.x, result.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_optimization_results(best_coeffs, min_rmse, optimization_method):\n",
    "\n",
    "    results_file = open(optimization_method +\".txt\", \"a\")\n",
    "    results_file.write(\"\\n\")\n",
    "    results_file.write(datetime.now().strftime(\"%I:%M%p on %B %d, %Y\"))\n",
    "    results_file.write(\"\\n\")\n",
    "    results_file.write(str(best_coeffs))\n",
    "    results_file.write(\"\\n\")\n",
    "    results_file.write(str(min_rmse))\n",
    "    results_file.write(\"\\n\")\n",
    "\n",
    "    coeffs = _COEFFS\n",
    "    coeffs['mode0']['a1'] = best_coeffs[0].item()\n",
    "    coeffs['mode0']['a2'] = best_coeffs[1].item()\n",
    "    coeffs['mode0']['a3'] = best_coeffs[2].item()\n",
    "    coeffs['mode0']['a4'] = best_coeffs[3].item()\n",
    "\n",
    "    print(\"Best Coeffs: \" + str(coeffs))\n",
    "\n",
    "    p1203_best_qoe_dict = calculate_p1203_for_everything(input_json=input_json, current_coeffs=coeffs)\n",
    "    p1203_best_qoe_df = pd.DataFrame.from_dict(p1203_best_qoe_dict)\n",
    "\n",
    "    print(\"--p1203_best_qoe_df--\")\n",
    "    print(p1203_best_qoe_df)\n",
    "\n",
    "    ground_truth_filtered_df = vpcc_filtered_df\n",
    "\n",
    "    # First process the training data\n",
    "    process_p1203_and_groundtruth(p1203_df=p1203_best_qoe_df, ground_truth_df=ground_truth_filtered_df, filename_prefix=\"fine_tuned_\"+str(optimization_method), dataset_type=DatasetType.TRAINING, yaxis_label=\"FINE TUNED \"+str(optimization_method))\n",
    "\n",
    "    # Then procss the validation data\n",
    "    process_p1203_and_groundtruth(p1203_df=p1203_best_qoe_df, ground_truth_df=ground_truth_filtered_df, filename_prefix=\"fine_tuned_\"+str(optimization_method), dataset_type=DatasetType.VALIDATION, yaxis_label=\"FINE TUNED \"+str(optimization_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go over the optimization array/single method\n",
    "def do_all_optimization_methods(current_optimization_method,ground_truth_training_grouped_df):\n",
    "    if current_optimization_method is not None:\n",
    "        (best_coeffs, min_rmse) = optimize(current_optimization_method=current_optimization_method, ground_truth_training_grouped_df=ground_truth_training_grouped_df)\n",
    "        process_optimization_results(best_coeffs=best_coeffs, min_rmse=min_rmse, optimization_method=current_optimization_method)\n",
    "    else:\n",
    "        for optimization_method in optimization_methods:\n",
    "            do_all_optimization_methods(optimization_method,ground_truth_training_grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_string(dist):\n",
    "    if dist in distance_map_old.keys():\n",
    "        return distance_map_old[dist]\n",
    "    elif dist in distance_map_new.keys():\n",
    "        return distance_map_new[dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth_df contains all the ground truth data from the users\n",
    "# ground_truth_training_df contains the training ground truth data\n",
    "\n",
    "# only keep the useful columns\n",
    "ground_truth_df = ground_truth_df[['object', 'start_qual', 'end_qual', 'dist', 'rate']]\n",
    "ground_truth_df['dist'] = ground_truth_df['dist'].apply(lambda x: get_dist_string(x))\n",
    "\n",
    "configurations = ground_truth_df.groupby(groupby_columns, as_index=False)\n",
    "\n",
    "# for each configuration, filter outliers\n",
    "vpcc_filtered_df = None\n",
    "\n",
    "# for each data frame in the configurations, filter the outliers\n",
    "for _, frame in configurations:\n",
    "    vpcc_filtered_df = pd.concat([vpcc_filtered_df, boxplot_outlier_filter(frame)], axis=0)\n",
    "\n",
    "# reset the index of the filtered data frame\n",
    "vpcc_filtered_df = vpcc_filtered_df.reset_index(drop=True)\n",
    "\n",
    "print(\"--vpcc_filtered_df--\")\n",
    "print(vpcc_filtered_df) # THIS ONE IS THE FILTERED DATA WITH EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the ground truth training dataframe to the filtered data frame for the training objects\n",
    "ground_truth_training_filtered_df = vpcc_filtered_df.loc[vpcc_filtered_df['object'].isin(training_object_names)]\n",
    "\n",
    "print(\"--ground_truth_training_filtered_df--\")\n",
    "print(ground_truth_training_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the filtered training dataframe\n",
    "ground_truth_training_grouped_df = ground_truth_training_filtered_df.groupby(groupby_columns, as_index=False).aggregate(lambda x: tuple(x))\n",
    "\n",
    "print(\"--ground_truth_training_grouped_df--\")\n",
    "print(ground_truth_training_grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_all_optimization_methods(current_optimization_method, ground_truth_training_grouped_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
